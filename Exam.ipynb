{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rohan\\Downloads\\Data_Board_Mask New.txt')\n",
    "#df.to_csv(r'C:\\Users\\rohan\\Downloads\\Data_Board_Mask_New.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_chunk_size = df.shape[0]/49  #total number of students in the class is 49\n",
    "low_chunk_size = math.ceil(per_chunk_size*24) #24th student in the attendance list\n",
    "high_chunk_size = math.ceil(low_chunk_size+per_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beacdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunk = df[low_chunk_size,high_chunk_size]\n",
    "new_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunk.to_csv(r'C:\\Users\\rohan\\Downloads\\file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the values of the rows which has NA in it since there are NA values in the places where there is text and if we make them as zero the data would not be more clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28719",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_clean=new_chunk.dropna(axis=0, how= 'any')      \n",
    "file_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recoding all the columns in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.directors_name.unique())}\n",
    "file_clean['directors_name_recoded']= file_clean['directors_name'].map(directors_name_dict)\n",
    "#directors_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "committee_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.committee_name.unique())}\n",
    "file_clean['committee_name_recoded']= file_clean['committee_name'].map(committee_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation_full_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.designation_full_name.unique())}\n",
    "file_clean['designation_full_name_recoded']= file_clean['designation_full_name'].map(designation_full_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ae26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.category.unique())}\n",
    "file_clean['category_recoded']= file_clean['category'].map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_non_exec_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.exec_non_exec_category.unique())}\n",
    "file_clean['exec_non_exec_category_recoded']= file_clean['exec_non_exec_category'].map(exec_non_exec_category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_non_prom_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.prom_non_prom_category.unique())}\n",
    "file_clean['prom_non_prom_category_recoded']= file_clean['prom_non_prom_category'].map(prom_non_prom_category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_non_prom_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.prom_non_prom_category.unique())}\n",
    "file_clean['prom_non_prom_category_recoded']= file_clean['prom_non_prom_category'].map(prom_non_prom_category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_agm_attended_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean.last_agm_attended.unique())}\n",
    "file_clean['last_agm_attended_recoded']= file_clean['last_agm_attended'].map(last_agm_attended_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490be2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data = file_clean)\n",
    "df1.to_csv(r'C:\\Users\\rohan\\Downloads\\file2.csv') \n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c74d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4502eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_chunk=df[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now here we have to remove NA and recoded these 10 records again so that we can append to the file since "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_clean_random=random_chunk.dropna(axis=0, how= 'any')      \n",
    "file_clean_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fee893",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.directors_name.unique())}\n",
    "file_clean_random['directors_name_recoded']= file_clean['directors_name'].map(directors_name_dict)\n",
    "\n",
    "committee_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.committee_name.unique())}\n",
    "file_clean_random['committee_name_recoded']= file_clean['committee_name'].map(committee_name_dict)\n",
    "\n",
    "designation_full_name_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.designation_full_name.unique())}\n",
    "file_clean_random['designation_full_name_recoded']= file_clean['designation_full_name'].map(designation_full_name_dict)\n",
    "\n",
    "category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.category.unique())}\n",
    "file_clean_random['category_recoded']= file_clean['category'].map(category_dict)\n",
    "\n",
    "exec_non_exec_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.exec_non_exec_category.unique())}\n",
    "file_clean_random['exec_non_exec_category_recoded']= file_clean['exec_non_exec_category'].map(exec_non_exec_category_dict)\n",
    "\n",
    "prom_non_prom_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.prom_non_prom_category.unique())}\n",
    "file_clean_random['prom_non_prom_category_recoded']= file_clean['prom_non_prom_category'].map(prom_non_prom_category_dict)\n",
    "\n",
    "prom_non_prom_category_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.prom_non_prom_category.unique())}\n",
    "file_clean_random['prom_non_prom_category_recoded']= file_clean['prom_non_prom_category'].map(prom_non_prom_category_dict)\n",
    "\n",
    "last_agm_attended_dict = {value:\"0\"+str(idx+1).zfill(2) for idx , value in enumerate(file_clean_random.last_agm_attended.unique())}\n",
    "file_clean_random['last_agm_attended_recoded']= file_clean['last_agm_attended'].map(last_agm_attended_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b227e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that the data is cleaned we can append the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_chunk=file_clean.append(file_clean_random)\n",
    "new_data_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_chunk.to_csv(r'C:\\Users\\rohan\\Downloads\\file3.csv') \n",
    "new_data_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbaa770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ce4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =pd.read_csv(r'C:\\Users\\rohan\\Downloads\\file3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d051460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the mean of the salary using stats['Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame()\n",
    "#stats = df.iloc[:,8].mean()\n",
    "stats['Mean'] = df.iloc[:,7:11].mean()\n",
    "mean= stats['Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c955fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buoyancy(salary,tr):\n",
    "    if salary >= mean and tr >= 500000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc will give the every row in 8th coulmn and every row in 10th coulmn will be passed to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "buoyancy = []\n",
    "for i in range(df3.shape[0]):\n",
    "    buoyancy.append(get_buoyancy(df3.iloc[i,8],df3.iloc[i,10]))\n",
    "df3['buoyancy'] = buoyancy\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(r'C:\\Users\\rohan\\Downloads\\file3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
